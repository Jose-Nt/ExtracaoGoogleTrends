{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f31c1c4c",
   "metadata": {},
   "source": [
    "## Aquisição de dados do Google Trends\n",
    "- O script foi desenvolvido baseando-se no download dos arquivos .csv disponilizados pelo próprio Google Trends;\n",
    "- A escolha mencionada foi tomada com o intuito de facilitar a aquisição dos dados, evitando interações mais diretas com o HTML da página;\n",
    "- Os arquivos .csv são baixados e posteriormente seus dados são interpretados em dataframes;\n",
    "- Os dataframes são manipulados seguindo algumas especificações e posteriormente é feito o upload dos dados para o postgres;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "eafe855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Bibliotecas a serem utilizadas\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from sqlalchemy import create_engine\n",
    "from selenium import webdriver\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import os as os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a9c331",
   "metadata": {},
   "source": [
    "### *1.0 - Criação de diretórios e definição de destino padrão para download*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5712cd6d",
   "metadata": {},
   "source": [
    "#### Criação de diretórios específicos com a biblioteca os\n",
    "- Criando diretório 'trends_api' caso o mesmo não exista;\n",
    "- O diretório 'trends_api' servirá como destino padrão dos downloads dos arquivos csv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "139deee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Criando pasta para armanezar os arquivos csv baixados\n",
    "pasta = 'trends_api'\n",
    "endereco = os.path.join(os.path.expanduser(\"~\"), pasta)\n",
    "\n",
    "if not os.path.exists(pasta):\n",
    "    os.mkdir(pasta)\n",
    "    \n",
    "#===Definindo caminho para download dos arquivos csv\n",
    "opcoes = Options()\n",
    "\n",
    "prefs = {'download.default_directory': endereco}\n",
    "opcoes.add_experimental_option('prefs', prefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894095e3",
   "metadata": {},
   "source": [
    "### *2.0 - Download dos arquivos e criação de DataFrames provisórios*\n",
    "#### Navegando na página com selenium e realizando downloads\n",
    "- Caso o site seja acessado diretamente com (url + pesquisa) será automaticamente barrado, por isso a navegação passo a passo;\n",
    "- A variável 'termo' se refere ao termo sobre o qual serão adquiridas as informações de tendências;\n",
    "- As variáveis 'intervaloDe' e 'intervaloAte' se referem ao intervalo de tempo que os dados serão extraídos ('intervaloDe: data de início; intervaloAte: data de término);\n",
    "- Os botões de pesquisa, filtragem e download são locaizados através de seus xpath's;\n",
    "- Devido ao fato de que caso hajam falhas de conexão com a internet os campos xpath não vão ser encontrados, a estrutura de busca é feita para iterar até 10 vezes sobre a página em caso de erros por falha de conexão;\n",
    "- É possível diminuir os tempos de sleep de acordo com a qualidade atual da conexão com a internet;\n",
    ">IMPORTANTE: Os dados de data devem ser inseridos no formato MES/DIA/ANO e não existem dados disponíveis anteriores ao ano de 2004. Além disso, o código não funciona caso esteja em modo headless, uma vez que é necessário que carreguem alguns recursos gráficos para que funcione;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "4d41be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================Definindo parâmetros====================#\n",
    "termo = 'tatu'\n",
    "intervaloDe = '09/20/2021'\n",
    "intervaloAte = '09/22/2023'\n",
    "\n",
    "\n",
    "flag_concluido = False\n",
    "for i in range(9):\n",
    "    try:    \n",
    "        #==========Navegando pela página\n",
    "        url = 'https://trends.google.com.br'\n",
    "        navegador = webdriver.Chrome(options=opcoes)\n",
    "            \n",
    "        navegador.get(url)\n",
    "        sleep(2)\n",
    "        navegador.find_element('xpath', '//*[@id=\"i9\"]').click()\n",
    "        sleep(2)\n",
    "        navegador.find_element('xpath', '//*[@id=\"i9\"]').send_keys(termo)\n",
    "        sleep(2)\n",
    "        navegador.find_element('xpath', '//*[@id=\"yDmH0d\"]/c-wiz/div/div[2]/div[4]/div[1]/c-wiz[1]/div/div[1]/div[3]/div/div[2]/div[3]/div/button/span[6]').click()\n",
    "        sleep(2)\n",
    "        navegador.find_element('xpath', '//*[@id=\"select_value_label_9\"]/span[1]/div').click()\n",
    "        sleep(2)\n",
    "\n",
    "        #==========Fechando possível cookie\n",
    "        try:\n",
    "            navegador.find_element('xpath','//*[@id=\"cookieBar\"]/div/span[2]/a[2]').click()\n",
    "            sleep(1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #==========Definindo intervalo de tempo\n",
    "        navegador.find_element('xpath', '/html/body/div[8]/md-select-menu/md-content/md-option[10]/div').click()\n",
    "        sleep(3)\n",
    "\n",
    "        nums = ['1', '2']\n",
    "        intervalos = [intervaloDe, intervaloAte]\n",
    "        for i in range(len(nums)):\n",
    "            navegador.find_element('xpath', f'/html/body/div[2]/div[4]/md-dialog/md-tabs/md-tabs-content-wrapper/md-tab-content[1]/div/md-content/form/div[{nums[i]}]/md-datepicker/div/input').clear()\n",
    "            sleep(2)\n",
    "            navegador.find_element('xpath', f'/html/body/div[2]/div[4]/md-dialog/md-tabs/md-tabs-content-wrapper/md-tab-content[1]/div/md-content/form/div[{nums[i]}]/md-datepicker/div/input').send_keys(intervalos[i])\n",
    "            sleep(2)\n",
    "\n",
    "        navegador.find_element('xpath', '/html/body/div[2]/div[4]/md-dialog/md-dialog-actions/button[2]').click()\n",
    "        sleep(5)\n",
    "\n",
    "        #==========Realizando downloads\n",
    "        nums = ['1','2','3']\n",
    "        for num in nums:\n",
    "            buttom = f'/html/body/div[2]/div[2]/div/md-content/div/div/div[{num}]/trends-widget/ng-include/widget/div/div/div/widget-actions/div/button[1]/i'\n",
    "            navegador.find_element('xpath', buttom).click()\n",
    "            sleep(4)\n",
    "            \n",
    "        flag_concluido = True\n",
    "        navegador.quit()\n",
    "        break\n",
    "        \n",
    "    except:\n",
    "        navegador.quit()\n",
    "        pass\n",
    "    \n",
    "#==========Checagem se os arquivos foram baixados ou não\n",
    "if flag_concluido == False:\n",
    "    print('''ERRO:Os arquivos não foram baixados. \n",
    "    Prováveis causas: \n",
    "    1 - Identificação dos xpath's (mudança no html da página);\n",
    "    2 - Erro de inserção dos dados de 'intervaloDe' e 'intervaloAte';\n",
    "    3 - Conexão muito instável com a internet impossibilitou o carregamento dos xpath's;\n",
    "    ''')\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149488f5",
   "metadata": {},
   "source": [
    "#### Criando DataFrames provisórios com os arquivos csv\n",
    "- Criação de 3 dataframes referentes, respectivamente, aos dados de interesse por sub região, assuntos relacionados e interesse por data;\n",
    "- Os parâmetros na criação do dataframe são passados a fim de corrirgir especificidades de cada csv cedido pelo Google Trends;\n",
    "- Os dataframes provisórios tem a terminação 'PROV' a fim de facilitar sua identificação;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "428f6b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Criando dataframes\n",
    "arquivos = ['geoMap.csv', 'relatedEntities.csv', 'multiTimeline.csv']\n",
    "\n",
    "#===Interesse por sub região\n",
    "try:\n",
    "    df_subRegiaoPROV = pd.read_csv(f'{endereco}\\\\{arquivos[0]}', delimiter=',', skiprows=3, header=None, encoding='utf-8')\n",
    "    colunas_sub = ['estado','interesse']\n",
    "    df_subRegiaoPROV.columns = colunas_sub\n",
    "except:\n",
    "    df_subRegiaoPROV = pd.DataFrame(columns={'estado':[],'interesse':[]})\n",
    "  \n",
    "#===Assuntos relacionados\n",
    "try:\n",
    "    df_assuntosRelacPROV = pd.read_csv(f'{endereco}\\\\{arquivos[1]}', delimiter=',', skiprows=4, header=None, encoding='utf-8')\n",
    "    colunas_assu = ['assunto', 'interesse']\n",
    "    df_assuntosRelacPROV.columns = colunas_assu\n",
    "except:\n",
    "    df_assuntosRelacPROV = pd.DataFrame(columns={'assunto':[],'interesse':[]})\n",
    "\n",
    "#===Interesse por data\n",
    "try:\n",
    "    df_interesseDataPROV = pd.read_csv(f'{endereco}\\\\{arquivos[2]}', skiprows=3, header=None, encoding='utf-8')\n",
    "    colunas = ['data','interesse']\n",
    "    df_interesseDataPROV.columns = colunas\n",
    "except:\n",
    "    df_interesseDataPROV = pd.DataFrame(columns={'data':[],'interesse':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9297e16a",
   "metadata": {},
   "source": [
    "### *3.0 Tratamento dos DataFrames provisórios*\n",
    "#### Tratando dataframe de assuntos relacionados ao termo e porcentagens de aumento\n",
    "- O arquivo .csv possui dados os quais refletem o aumento da tendência de pesquisa em porcentagem, fugindo do padrão numérico de interesse;\n",
    "- O dataframe foi filtrado deixando somente as linhas que seguem o padrão numérico de interesse (1 a 100), então valores menores que 1, porcentagens ou caracteres foram excluídos;\n",
    "- Os dados que possuíam porcentagem (caso existam) foram armazenados no data frame 'df_aumentAssuntoPROV';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "c7dfaf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============Tratamento dos dados do dataframe de assuntos relacionados===============#\n",
    "list_assuntosPorc = []\n",
    "list_valoresPorc = []\n",
    "\n",
    "list_assuntos = []\n",
    "list_valores = []\n",
    "\n",
    "#===Separação dos dados para criação do dataframe de porcentagens\n",
    "nums = ['1','2','3','4','5','6','7','8','9','0']\n",
    "for i in range(len(df_assuntosRelacPROV)):\n",
    "    valor = df_assuntosRelacPROV['interesse'].iloc[i]\n",
    "    assunto = df_assuntosRelacPROV['assunto'].iloc[i]\n",
    "    valor2 = (str(valor))[-1]\n",
    "    valor1 = (str(valor))[0]\n",
    "    \n",
    "    if valor1 in nums:\n",
    "        list_valores.append(valor)\n",
    "        list_assuntos.append(assunto)\n",
    "    elif valor2 == '%':\n",
    "        list_valoresPorc.append(valor)\n",
    "        list_assuntosPorc.append(assunto)\n",
    "\n",
    "#===Criação dos novos dataframes\n",
    "df_aumentAssuntoPROV = pd.DataFrame({'assunto': list_assuntosPorc, 'aumento': list_valoresPorc})\n",
    "df_assuntosRelacPROV = pd.DataFrame({'assunto' : list_assuntos, 'interesse' : list_valores})\n",
    "\n",
    "\n",
    "#===============Tratamento do dataframe de porcentagens (retirando caracteres não numéricos)===============#\n",
    "list_provisoria_valores = []\n",
    "list_assunto = []\n",
    "    \n",
    "for i in range(len(df_aumentAssuntoPROV)):\n",
    "    list_provisoria_valores.append(df_aumentAssuntoPROV['aumento'].iloc[i])\n",
    "    list_assunto.append(df_aumentAssuntoPROV['assunto'].iloc[i])\n",
    "    \n",
    "#===Tratando as células e removendo caracteres que não sejam numéricos\n",
    "lista_porcentagens = []\n",
    "nums = '1234567890'\n",
    "for i in range(len(list_provisoria_valores)):\n",
    "    string = list(list_provisoria_valores[i])\n",
    "    for i in range(len(string)):\n",
    "        if string[i] not in nums:\n",
    "            string[i] = ''\n",
    "    string_final = ''.join(string)\n",
    "    lista_porcentagens.append(string_final)\n",
    "\n",
    "#===Substituindo valores já corrigidos dentro do dataframe de aumento de porcentagem\n",
    "for i in range(len(df_aumentAssuntoPROV)):\n",
    "    valor = df_aumentAssuntoPROV['aumento'].iloc[i]\n",
    "    df_aumentAssuntoPROV['aumento'].iloc[i] = df_aumentAssuntoPROV['aumento'].iloc[i].replace(valor, lista_porcentagens[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b6b50",
   "metadata": {},
   "source": [
    "#### Tratamento de dados numéricos inteiros nas tabelas de subregiao e interesse por data\n",
    "- Alguns valores podem conter o sinal '<', portanto é necessário que os mesmos sejam tratados;\n",
    "- A fim de simplificação, esses dados foram substituídos por números 0, o que significa que há pouco (menos que um ponto) ou nenhum interesse;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "2d6b92c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = ['1','2','3','4','5','6','7','8','9','0']\n",
    "\n",
    "#===Redefinindo tipos de data para ser possível a atuação do .replace()\n",
    "df_subRegiaoPROV['interesse'] = df_subRegiaoPROV['interesse'].astype(str)\n",
    "df_interesseDataPROV['interesse'] = df_interesseDataPROV['interesse'].astype(str)\n",
    "\n",
    "#===Replace dataframe de interesse por sub regiao\n",
    "for i in range(len(df_subRegiaoPROV)):\n",
    "    valor = df_subRegiaoPROV['interesse'].iloc[i]\n",
    "    valor1 = (str(valor))[0]\n",
    "    \n",
    "    if valor1 not in nums:\n",
    "        df_subRegiaoPROV['interesse'].iloc[i] = df_subRegiaoPROV['interesse'].iloc[i].replace(valor, '0')\n",
    " \n",
    "\n",
    "#===Replace dataframe de interesse por assunto relacionado\n",
    "for i in range(len(df_interesseDataPROV)):\n",
    "    valor = df_interesseDataPROV['interesse'].iloc[i]\n",
    "    valor1 = (str(valor))[0]\n",
    "    \n",
    "    if valor1 not in nums:\n",
    "        df_interesseDataPROV['interesse'].iloc[i] = df_interesseDataPROV['interesse'].iloc[i].replace(valor, '0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c714d535",
   "metadata": {},
   "source": [
    "#### Ajustando dados não inteiros nas colunas de quantidade de interesse\n",
    "- Algumas vezes o site google trends fornece dados com formato '2.0' (float), o que impede que o restante do código seja executado, isso está sendo corrigido aqui;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "841ccc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [df_subRegiaoPROV, df_interesseDataPROV, df_assuntosRelacPROV]\n",
    "\n",
    "#===Substituindo dados nan por '0' para evitar possíveis erros\n",
    "for dataframe in dataframes:\n",
    "    dataframe['interesse'] = dataframe['interesse'].fillna(0)\n",
    "\n",
    "#===Transformando dados float em int\n",
    "for dataframe in dataframes:\n",
    "    for j in range(len(dataframe)):\n",
    "        valor = dataframe['interesse'].iloc[j]\n",
    "        valorRep = float(valor)\n",
    "        valorRep = int(valorRep)\n",
    "        valorRep = str(valorRep)\n",
    "        dataframe['interesse'].iloc[j] = dataframe['interesse'].iloc[j].replace(valor, valorRep)\n",
    "\n",
    "#===Excessão para o dataframe 'df_aumentAssuntoPROV' pois o mesmo não possui o mesmo nome de coluna que os demais \n",
    "df_aumentAssuntoPROV['aumento'] = df_aumentAssuntoPROV['aumento'].fillna(0)\n",
    "\n",
    "for i in range(len(df_aumentAssuntoPROV)):\n",
    "    valor = df_aumentAssuntoPROV['aumento'].iloc[i]\n",
    "    valorRep = float(valor)\n",
    "    valorRep = int(valorRep)\n",
    "    valorRep = str(valorRep)\n",
    "    df_aumentAssuntoPROV['aumento'].iloc[i] = df_aumentAssuntoPROV['aumento'].iloc[i].replace(valor, valorRep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce1029a",
   "metadata": {},
   "source": [
    "### *4.0 - Criação dos DataFrames  finais*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe28600",
   "metadata": {},
   "source": [
    "#### Criação dos dataframes finais para posterior upload\n",
    "- A respeito do dataframe de interesse por UF, o mesmo possui as colunas de intervalo de tempo (data de início da pesquisa e data de fim da pesquisa), o termo buscado, a unidade federativa e a quantidade de interesse;\n",
    "- Já o dataframe de interesse por data terá as colunas de intervalo de tempo (data de início da pesquisa e data de fim da pesquisa), data de registro, termo buscado e quantidade de interesse;\n",
    "- A respeito do dataframe de interesse por assunto relacionado, o mesmo terá as colunas de intervalo de tempo (data de início da pesquisa e data de fim da pesquisa), o termo buscado, assunto relacionado e quantidade de interesse;\n",
    "- Por fim, o dataframe de porcentage de aumento do interesse por assunto possuirá as colunas de intervalo de tempo (data de início e data de término), o termo pesquisado, assunto e a quantidade em porcentagem do aumento de interesse;\n",
    "> Vale destacar que os dados de aumento de interesse em porcentagem se referem SOMENTE a pesquisas que tiveram um aumento REPENTINO dentro o intervalo estipulado;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "58096b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============Criação do dataframe de interesse por UF 'df_subReg'===============#\n",
    "colunas = ['Data_Inicio', 'Data_Fim', 'Termo_Busca', 'UF', 'Quant_Interesse']\n",
    "df_subReg = pd.DataFrame(columns = colunas)\n",
    "\n",
    "datainic = []\n",
    "datafim = []\n",
    "termobuscas = []\n",
    "interesses = []\n",
    "estados = []\n",
    "\n",
    "for i in range(len(df_subRegiaoPROV)):\n",
    "    estados.append(df_subRegiaoPROV['estado'].iloc[i])\n",
    "    interesses.append(df_subRegiaoPROV['interesse'].iloc[i])\n",
    "    datainic.append(intervaloDe)\n",
    "    datafim.append(intervaloAte)\n",
    "    termobuscas.append(termo)\n",
    "\n",
    "lista_auxiliar = [datainic, datafim, termobuscas, estados, interesses]\n",
    "for i in range(len(lista_auxiliar)):\n",
    "    df_subReg[colunas[i]] = lista_auxiliar[i]\n",
    "    \n",
    "#===============Criação do dataframe de interesse por data 'df_dataInteresse'===============#\n",
    "colunas = ['Intervalo_De','Intervalo_Ate','Data_Registro', 'Termo_Busca', 'Quant_Interesse']\n",
    "df_dataInteresse = pd.DataFrame(columns = colunas)\n",
    "\n",
    "datas = []\n",
    "termobuscas = []\n",
    "datainic = []\n",
    "datafim = []\n",
    "interesses = []\n",
    "\n",
    "for i in range(len(df_interesseDataPROV)):\n",
    "    datas.append(df_interesseDataPROV['data'].iloc[i])\n",
    "    interesses.append(df_interesseDataPROV['interesse'].iloc[i])\n",
    "    termobuscas.append(termo)\n",
    "    datainic.append(intervaloDe)\n",
    "    datafim.append(intervaloAte)\n",
    "\n",
    "lista_auxiliar = [datainic, datafim, datas, termobuscas, interesses]\n",
    "for i in range(len(lista_auxiliar)):  \n",
    "    df_dataInteresse[colunas[i]] = lista_auxiliar[i]\n",
    "\n",
    "    \n",
    "#===============Criação do dataframe de interesse por assunto relacionado 'df_assuntoRelac'===============#\n",
    "colunas = ['Data_Inicio', 'Data_Fim', 'Termo_Busca', 'Assunto_Relacionado', 'Quant_Interesse']\n",
    "df_assuntoRelac = pd.DataFrame(columns = colunas)\n",
    "\n",
    "datainic = []\n",
    "datafim = []\n",
    "termobuscas = []\n",
    "interesses = []\n",
    "assuntos = []\n",
    "\n",
    "for i in range(len(df_assuntosRelacPROV)):\n",
    "    assuntos.append(df_assuntosRelacPROV['assunto'].iloc[i])\n",
    "    interesses.append(df_assuntosRelacPROV['interesse'].iloc[i])\n",
    "    datainic.append(intervaloDe)\n",
    "    datafim.append(intervaloAte)\n",
    "    termobuscas.append(termo)\n",
    "\n",
    "lista_auxiliar = [datainic, datafim, termobuscas, assuntos, interesses]\n",
    "for i in range(len(lista_auxiliar)):  \n",
    "      df_assuntoRelac[colunas[i]] = lista_auxiliar[i]\n",
    "\n",
    "#===============Criação do dataframe de porcentagem de aumento por termo de pesquisa 'df_aumentoAssunto'====================#\n",
    "colunas = ['Data_Inicio', 'Data_Fim', 'Termo_Busca', 'Assunto', 'Porcentagem_Aumento']\n",
    "df_aumentoAssunto = pd.DataFrame(columns = colunas)\n",
    "    \n",
    "datainic = []\n",
    "datafim = []\n",
    "termobuscas = []\n",
    "assunto = []\n",
    "    \n",
    "for i in range(len(df_aumentAssuntoPROV)):\n",
    "    assunto.append(df_aumentAssuntoPROV['assunto'].iloc[i])\n",
    "    datainic.append(intervaloDe)\n",
    "    datafim.append(intervaloAte)\n",
    "    termobuscas.append(termo)\n",
    "    \n",
    "lista_auxiliar = [datainic, datafim, termobuscas, assunto, lista_porcentagens]\n",
    "for i in range(len(lista_auxiliar)):\n",
    "    df_aumentoAssunto[colunas[i]] = lista_auxiliar[i] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7cea40",
   "metadata": {},
   "source": [
    "#### Redefinindo os tipos de dado de cada coluna\n",
    "- Redefinição dos tipos de dados por culuna colocando os dados de quantidade de interesse como 'int', os dados que são texto como 'object' e as datas como 'datetime' (com excessão da coluna de data_registro, a mesma foi classificada como 'timestamp with time zone';\n",
    "- Caso os valores de interesse por estado estejam vazios eles são preenchidos com 0 para posterior conversão dos dados;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "8abe9532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====DataFrame df_aumentoAssunto=====#\n",
    "colunas_aumentoAssunto = {\n",
    "    'Porcentagem_Aumento': int,\n",
    "    'Termo_Busca': object,\n",
    "    'Assunto': object,\n",
    "    'Data_Inicio': 'date',\n",
    "    'Data_Fim': 'date'\n",
    "}\n",
    "\n",
    "#=====DataFrame df_subReg=====#\n",
    "colunas_subReg = {\n",
    "    'Quant_Interesse': int,\n",
    "    'Termo_Busca': object,\n",
    "    'UF': object,\n",
    "    'Data_Inicio': 'date',\n",
    "    'Data_Fim': 'date'\n",
    "}\n",
    "\n",
    "#=====DataFrame df_dataInteresse=====#\n",
    "colunas_dataInteresse = {\n",
    "    'Intervalo_De': 'date',\n",
    "    'Intervalo_Ate': 'date',\n",
    "    'Data_Registro': 'date',\n",
    "    'Termo_Busca': object,\n",
    "    'Quant_Interesse': int\n",
    "}\n",
    "\n",
    "#=====DataFrame df_assuntoRelac=====#\n",
    "colunas_assuntoRelac = {\n",
    "    'Quant_Interesse': int,\n",
    "    'Data_Inicio': 'date',\n",
    "    'Data_Fim': 'date',\n",
    "    'Termo_Busca': object,\n",
    "    'Assunto_Relacionado': object\n",
    "}\n",
    "\n",
    "#===============Convertendo os tipos de dados das colunas===============#\n",
    "def conversor_colunas(dataframe, conversoes):\n",
    "    for coluna, tipo_de_dado in conversoes.items():\n",
    "        if tipo_de_dado == 'date':\n",
    "            dataframe[coluna] = pd.to_datetime(dataframe[coluna])\n",
    "        else:\n",
    "            dataframe[coluna] = dataframe[coluna].astype(tipo_de_dado)\n",
    "\n",
    "df_subReg = df_subReg.fillna(0)\n",
    "\n",
    "conversor_colunas(df_aumentoAssunto, colunas_aumentoAssunto)\n",
    "conversor_colunas(df_dataInteresse, colunas_dataInteresse)\n",
    "conversor_colunas(df_assuntoRelac, colunas_assuntoRelac)\n",
    "conversor_colunas(df_subReg, colunas_subReg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee963f",
   "metadata": {},
   "source": [
    "### *5.0 - Upload dos dataframes para o banco de dados*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864bf6a4",
   "metadata": {},
   "source": [
    "#### Upload dos dataframes para o banco de dados postgres\n",
    "- Estabelecendo a conexão com o banco de dados postgres;\n",
    "- Com a conexão estabelecida, são criadas as 4 tabelas de dados dentro do banco de dados tendo seus nomes formados por 'termo de pesquisa' + 'início do seu tipo de dado' + 'número da execução';\n",
    "- Após a criação das tabelas, é feito o upload de cada dataframe para sua respectiva tabela;\n",
    "- Depois de todo o processo feito, os arquivos csv originais são apagados a fim de evitar inconsistências nas próximas execuções;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "2c31c070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão com o banco de dados \"testegoogletrends\" estabelecia\n"
     ]
    }
   ],
   "source": [
    "#===Estabelecendo conexão com banco de dados\n",
    "host = 'SEU HOST'\n",
    "dbname = 'NOME DA BASE DE DADOS PARA ONDE OS DADOS VÃO'\n",
    "user = 'SEU USUÁRIO'\n",
    "password = 'SUA SENHA'\n",
    "sslmode = ''\n",
    "port = ''\n",
    "\n",
    "conect_string = 'host={} user={} dbname={} password={} sslmode={}'.format(host, user, dbname, password, sslmode)\n",
    "conec = pg.connect(conect_string)\n",
    "cursor = conec.cursor()\n",
    "print(f'Conexão com o banco de dados \"{dbname}\" estabelecia')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfb84be",
   "metadata": {},
   "source": [
    "#### Criação de tabelas\n",
    "- Caso ainda não existam, são criadas as tabelas 'aumento_assunto', 'sub_regiao', 'interesse_por_data' e 'assunto_relacionado' dentro do banco de dados;\n",
    "- As tabelas armanezam, respectivamente, os dados de porcentagem de aumento do interesse por assunto, interesse por sub região, interesse geral por intervalo de tempo específico, e assunto relacionado;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "6cbaf8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Criando tabelas dentro do banco de dados\n",
    "nomes_tabelas = ['aumento_assunto', 'sub_regiao', 'interesse_por_data', 'assunto_relacionado']\n",
    "\n",
    "#===============Tabela Aumento_Assunto===============#\n",
    "consulta_criar_tabela = f'''\n",
    "CREATE TABLE IF NOT EXISTS {nomes_tabelas[0]} (\n",
    "    Data_Inicio date,\n",
    "    Data_Fim date,\n",
    "    Termo_Busca varchar,\n",
    "    Assunto varchar,\n",
    "    Porcentagem_Aumento int\n",
    ");\n",
    "'''\n",
    "cursor.execute(consulta_criar_tabela)\n",
    "conec.commit()\n",
    "\n",
    "#===============Tabela Interesse_Por_Data===============#\n",
    "consulta_criar_tabela = f'''\n",
    "CREATE TABLE IF NOT EXISTS {nomes_tabelas[2]} (\n",
    "    Intervalo_De date,\n",
    "    Intervalo_Ate date,\n",
    "    Data_Registro timestamp with time zone,\n",
    "    Termo_Busca varchar,\n",
    "    Quant_Interesse int\n",
    ");\n",
    "'''\n",
    "cursor.execute(consulta_criar_tabela)\n",
    "conec.commit()\n",
    "\n",
    "#===============Tabela Sub_Regiao===============#\n",
    "consulta_criar_tabela = f'''\n",
    "CREATE TABLE IF NOT EXISTS {nomes_tabelas[1]} (\n",
    "    Data_Inicio date,\n",
    "    Data_Fim date,\n",
    "    Termo_Busca varchar,\n",
    "    UF varchar,\n",
    "    Quant_Interesse int\n",
    ");\n",
    "'''\n",
    "cursor.execute(consulta_criar_tabela)\n",
    "conec.commit()\n",
    "\n",
    "#===============Tabela Assunto_Relacionado===============#\n",
    "consulta_criar_tabela = f'''\n",
    "CREATE TABLE IF NOT EXISTS {nomes_tabelas[3]} (\n",
    "    Data_Inicio date,\n",
    "    Data_Fim date,\n",
    "    Termo_Busca varchar,\n",
    "    Assunto_Relacionado varchar,\n",
    "    Quant_Interesse int\n",
    ");\n",
    "'''\n",
    "cursor.execute(consulta_criar_tabela)\n",
    "conec.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf38054",
   "metadata": {},
   "source": [
    "#### Salvando dados dos DataFrames dentro das tabelas do banco de dados;\n",
    "- Na coluna de sub região, caso o primeiro elemento da quantidade de interesse seja 0, significa que não haviam dados de interesse por estado sucientes para serem analisados, o que implica na não adição desses dados ao banco de dados. Nas outras tabelas isso é feito de forma automática;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "abbc1bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe \"aumento_assunto\" salvo com sucesso\n",
      "dataframe \"sub_regiao\" salvo com sucesso\n",
      "dataframe \"assunto_relacionado\" salvo com sucesso\n",
      "dataframe \"interesse_por_data\" salvo com sucesso\n"
     ]
    }
   ],
   "source": [
    "nomes_tabelas = ['aumento_assunto', 'sub_regiao', 'interesse_por_data', 'assunto_relacionado']\n",
    "dataframes = [df_aumentoAssunto, df_subReg, df_dataInteresse, df_assuntoRelac]\n",
    "\n",
    "#===============Aumento do interesse por assunto relacionado===============#\n",
    "for index, linha in dataframes[0].iterrows():\n",
    "    consulta = f\"INSERT INTO {nomes_tabelas[0]} (Data_Inicio, Data_Fim, Termo_Busca, Assunto, Porcentagem_Aumento) VALUES (%s, %s, %s, %s, %s)\"\n",
    "    valores = (linha['Data_Inicio'], linha['Data_Fim'], linha['Termo_Busca'], linha['Assunto'], linha['Porcentagem_Aumento'])\n",
    "    cursor.execute(consulta, valores)\n",
    "conec.commit()\n",
    "print(f'dataframe \"{nomes_tabelas[0]}\" salvo com sucesso')\n",
    "\n",
    "#===============Sub região===============#\n",
    "for index, linha in dataframes[1].iterrows():\n",
    "    consulta = f\"INSERT INTO {nomes_tabelas[1]} (Data_Inicio, Data_Fim, Termo_Busca, UF, Quant_Interesse) VALUES (%s, %s, %s, %s, %s)\"\n",
    "    valores = (linha['Data_Inicio'], linha['Data_Fim'], linha['Termo_Busca'], linha['UF'], linha['Quant_Interesse'])\n",
    "    cursor.execute(consulta, valores)\n",
    "conec.commit()\n",
    "print(f'dataframe \"{nomes_tabelas[1]}\" salvo com sucesso')\n",
    "\n",
    "\n",
    "#===============Assunto relacionado===============#\n",
    "for index, linha in dataframes[3].iterrows():\n",
    "    consulta = f\"INSERT INTO {nomes_tabelas[3]} (Data_Inicio, Data_Fim, Termo_Busca, Assunto_Relacionado, Quant_Interesse) VALUES (%s, %s, %s, %s, %s)\"\n",
    "    valores = (linha['Data_Inicio'], linha['Data_Fim'], linha['Termo_Busca'], linha['Assunto_Relacionado'], linha['Quant_Interesse'])\n",
    "    cursor.execute(consulta, valores)\n",
    "conec.commit()\n",
    "print(f'dataframe \"{nomes_tabelas[3]}\" salvo com sucesso')\n",
    "\n",
    "\n",
    "#===============Interesse por data===============#\n",
    "for index, linha in dataframes[2].iterrows():\n",
    "    consulta = f\"INSERT INTO {nomes_tabelas[2]} (Intervalo_De, Intervalo_Ate, Data_Registro, Termo_Busca, Quant_Interesse) VALUES (%s, %s, %s, %s, %s)\"\n",
    "    valores = (linha['Intervalo_De'], linha['Intervalo_Ate'], linha['Data_Registro'], linha['Termo_Busca'], linha['Quant_Interesse'])\n",
    "    cursor.execute(consulta, valores)\n",
    "conec.commit()\n",
    "print(f'dataframe \"{nomes_tabelas[2]}\" salvo com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e2a11",
   "metadata": {},
   "source": [
    "#### Finalizando programa e apagando os arquivos csv baixados\n",
    "- Vale ressaltar que o código está sujeito a erros referentes a alterações no html da página do Google Trends após alguma aualização, sendo necessário uma manutenção para atualizar os xpath's;\n",
    "- Os parâmetros de tratamento e carga dos dados podem ser redefinidos facilmente para qualquer que seja a solicitação, bastando apenas uma manutenção simples (os dados podem ser interpretados e carregados em dicionários, tabelas únicas, comparações diferentes, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "a29ea29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O arquivo C:\\Users\\josen\\trends_api\\\\geoMap.csv foi excluído com sucesso.\n",
      "O arquivo C:\\Users\\josen\\trends_api\\\\multiTimeline.csv foi excluído com sucesso.\n",
      "O arquivo C:\\Users\\josen\\trends_api\\\\relatedEntities.csv foi excluído com sucesso.\n"
     ]
    }
   ],
   "source": [
    "#===Excluindo arquivos originais para permitir que o código seja executado novamente\n",
    "arquivos_excluir = ['geoMap.csv', 'multiTimeline.csv', 'relatedEntities.csv']\n",
    "\n",
    "for arquivo in arquivos_excluir:  \n",
    "    caminho_do_arquivo = f'{endereco}\\\\\\{arquivo}'\n",
    "    if os.path.exists(caminho_do_arquivo):\n",
    "        os.remove(caminho_do_arquivo)\n",
    "        print(f\"O arquivo {caminho_do_arquivo} foi excluído com sucesso.\")\n",
    "    else:\n",
    "        print(f\"O arquivo {caminho_do_arquivo} não existe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe3243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
